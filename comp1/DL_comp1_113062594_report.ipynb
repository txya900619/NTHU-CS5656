{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student ID: 113062594, name: 陳力瑋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Popularity                                       Page content\n",
      "0   0          -1  <html><head><div class=\"article-info\"> <span c...\n",
      "1   1           1  <html><head><div class=\"article-info\"><span cl...\n",
      "2   2           1  <html><head><div class=\"article-info\"><span cl...\n",
      "3   3          -1  <html><head><div class=\"article-info\"><span cl...\n",
      "4   4          -1  <html><head><div class=\"article-info\"><span cl...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How did you preprocess data\n",
    "- get title,auther_name,year,month,day,hour,weekday,see_also,see_also_num,contents,content_len \n",
    "- delete stop words in topic.\n",
    "- stem, and lemmatize degrade performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def preprocessor(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "\n",
    "    title = soup.body.h1.get_text(strip=True).lower()\n",
    "\n",
    "    topic = \" \".join(\n",
    "        [\n",
    "            category.get_text(strip=True).replace(\" \", \"-\").lower()\n",
    "            for category in soup.body.select(\".article-topics > a\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    author_name = soup.head.select_one(\".author_name > a\")\n",
    "    if author_name is None:\n",
    "        author_name = soup.head.select_one(\".author_name\")\n",
    "    if author_name is  None:\n",
    "        author_name = soup.head.select_one(\".article-info > span\")\n",
    "    if author_name is  None:\n",
    "        author_name = soup.head.select_one(\".article-info > a\")\n",
    "    author_name = author_name.get_text(strip=True).replace(\" \", \"-\").lower()\n",
    "    author_name = author_name.replace(\"by-\", \"\")\n",
    "    author_name = author_name.replace(\",-\", \" \")\n",
    "    author_name = author_name.replace(\"-and-\", \" \")\n",
    "    author_name = author_name.replace(\"-&-\", \" \")\n",
    "    author_name = author_name.replace(\"- \", \" \")\n",
    "    author_name = author_name.replace(\"--\", \" \")\n",
    "\n",
    "    date = soup.head.select_one(\"time\")\n",
    "    year = 0\n",
    "    month = 0\n",
    "    day = 0\n",
    "    hour = 25\n",
    "    weekday = 0\n",
    "    if date is not None and date.get_text(strip=True) != \"\":\n",
    "        date = datetime.strptime(date.get_text(strip=True).replace(\"UTC\", \"+0000\"), \"%Y-%m-%d %H:%M:%S %z\")\n",
    "        year = date.year\n",
    "        month = date.month\n",
    "        day = date.day\n",
    "        hour = date.hour\n",
    "        weekday = date.isoweekday()\n",
    "\n",
    "    # see_also and see_also_num no help\n",
    "    see_also = soup.body.select(\".see-also > a\")\n",
    "    see_also_num = 0\n",
    "    if see_also:\n",
    "        see_also_num = len(see_also)\n",
    "        see_also = \" \".join(\n",
    "            [\n",
    "                see_also.get_text(strip=True).lower()\n",
    "                for see_also in see_also\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        see_also = \"\"\n",
    "\n",
    "    # content no help\n",
    "    contents = \" \".join(\n",
    "        [\n",
    "            article_content.get_text(strip=True).lower()\n",
    "            for article_content in soup.body.select(\".article-content\")\n",
    "        ]\n",
    "    )\n",
    "    content_len = len(contents)\n",
    "\n",
    "\n",
    "    return title, topic, author_name, year, month, day, hour, content_len,see_also, see_also_num, contents, weekday\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"nasa's grand challenge: stop asteroids from destroying earth\", 'asteroid asteroids challenge earth space u.s. world', 'clara-moskowitz', 2013, 6, 19, 15, 3564, '', 0, 'there may be killer asteroids headed for earth, and nasa has decided to do something about it. the space agency announced a new \"grand challenge\" on june 18 to find all dangerous space rocks and figure out how to stop them from destroying our planet.the new mission builds on projects already underway at nasa, including a plan tocapture an asteroid, pull it in toward the moon and send astronauts to visit it. as part of the grand challenge, the agency issued a \"request for information\" today — aiming to solicit ideas from industry, academia and the public on how to improve the asteroid mission plan.\"we\\'re asking for you to think about concepts and different approaches for what we\\'ve described here,\" william gerstenmaier, nasa\\'s associate administrator for human explorations and operations, said yesterday during a nasa event announcing the initiative. \"we want you to think about other ways of enhancing this to get the most out of it.\"see also:how it works: nasa asteroid-captureresponses to the request for information, which also seeks ideas for detecting and mitigating asteroid threats, are due july 18.the asteroid-retrieval mission, designed to provide the first deep-space mission for astronauts flying on nasa\\'s space launch system rocket and orion space capsule under development, has come under fire from lawmakers who would prefer that nasa return to the moon.adraft nasa authorization billfrom the house space subcommittee, which is currently in debate, would cancel the mission and steer the agency toward other projects. that bill will be discussed during a hearing wednesday, june 19 at 10 a.m. edt.see also:how it works: nasa asteroid-capture mission in picturesbut nasa officials defended the asteroid mission today and said they were confident they\\'d win congress\\' support once they explained its benefits further.\"i think that we really, truly are going to be able to show the value of the mission,\" nasa associate administrator lori garver said today. \"to me, this is something that what we do in this country — we debate how we spend the public\\'s money. this is the beginning of the debate.\"garver also maintained that sending astronauts to an asteroid would not diminish nasa\\'s other science and exploration goals, including another lunar landing.see also:animation of proposed asteroid retrieval mission\"this initiative takes nothing from the other valuable work,\" she said. \"this is only a small piece of our overall strategy, but it is an integral piece. it takes nothing from the moon.\"part of nasa\\'s plan to win support for the flight is to link it more closely with the larger goal of protecting earth from asteroid threats.if, someday, humanity discovers an asteroid headed for earth and manages to alter its course, \"it will be one of the most important accomplishments in human history,\" said tom kalil, deputy director for technology and innovation at the white house office of science and technology policy.see also:wildest private deep-space mission ideas: a countdownthe topic of asteroid threats is more timely than ever, after a meteor exploded over the russian city ofchelyabinskon feb. 15 — the same day that the football field-sizedasteroid 2012 da14passed within the moon\\'s orbit of earth.image courtesy ofnasaspacex\\'s musk says sabotage unlikely cause of sept. 1 explosion, but still a worryproxima centauri is like our sun... on steroidschina launches shenzhou-11 astronauts to tiangong-2 space labspace station mockup in houston - astronaut guided tour | videothis article originally published at space.comhere', 3)\n"
     ]
    }
   ],
   "source": [
    "print(preprocessor(df.loc[0, \"Page content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [preprocessor(page_content) for page_content in df[\"Page content\"]]\n",
    "df_processed = pd.DataFrame(\n",
    "    features,\n",
    "    columns=[\n",
    "        \"title\",\n",
    "        \"topic\",\n",
    "        \"author_name\",\n",
    "        \"year\",\n",
    "        \"month\",\n",
    "        \"day\",\n",
    "        \"hour\",\n",
    "        \"content_len\",\n",
    "        \"see_also\",\n",
    "        \"see_also_num\",\n",
    "        \"contents\",\n",
    "        \"weekday\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['r']\n"
     ]
    }
   ],
   "source": [
    "def tokenizer(text):\n",
    "    return re.split(\"\\s+\", text[0].strip())\n",
    "\n",
    "\n",
    "print(tokenizer(\"runners like running and thus they run\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['r']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/wayne/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stop = stopwords.words(\"english\")\n",
    "\n",
    "\n",
    "def tokenizer_nostop(text):\n",
    "    return [\n",
    "        w\n",
    "        for w in re.split(\"\\s+\", text[0].strip())\n",
    "        if w not in stop and re.match(\"[a-zA-Z]+\", w)\n",
    "    ]\n",
    "\n",
    "\n",
    "print(tokenizer_nostop(\"runners like running and thus they run\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train = df_processed.values\n",
    "y_train = (df[\"Popularity\"].values == 1).astype(int)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I found only title, topic, year, month, day, hour, content_len, weekday can imporve performance\n",
    "- LGBMClassifier better than RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wayne/NTHU-CS5656/.venv/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/home/wayne/NTHU-CS5656/.venv/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "transformer = ColumnTransformer(\n",
    "    [\n",
    "        (\"title\", CountVectorizer(tokenizer=tokenizer, lowercase=False), [0]),\n",
    "        (\"topic\", CountVectorizer(tokenizer=tokenizer_nostop, lowercase=False), [1]),\n",
    "        (\"author_name\", \"drop\", [2]),\n",
    "        # (\"year\", \"drop\", [3]),\n",
    "        # (\"month\", \"drop\", [4]),\n",
    "        # (\"day\", \"drop\", [5]),\n",
    "        # (\"hour\", \"drop\", [6]),\n",
    "        # (\"content_len\", \"drop\", [7]),\n",
    "        (\"see_also\", \"drop\", [8]),\n",
    "        (\"see_also_num\", \"drop\", [9]),\n",
    "        (\"contents\", \"drop\", [10]),\n",
    "        # (\"weekday\", \"drop\", [11]),\n",
    "    ],\n",
    "    n_jobs=-1,\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "X_train = transformer.fit_transform(X_train)\n",
    "X_valid = transformer.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 1.00000\n",
      "valid score: 0.58336\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "forest = RandomForestClassifier(n_jobs=-1, random_state=0, n_estimators=400)\n",
    "\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "print(\n",
    "    \"train score: {:.5f}\".format(\n",
    "        roc_auc_score(y_train, forest.predict_proba(X_train)[:, 1])\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"valid score: {:.5f}\".format(\n",
    "        roc_auc_score(y_valid, forest.predict_proba(X_valid)[:, 1])\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10885, number of negative: 11229\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4507\n",
      "[LightGBM] [Info] Number of data points in the train set: 22114, number of used features: 1981\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492222 -> initscore=-0.031114\n",
      "[LightGBM] [Info] Start training from score -0.031114\n",
      "train score: 0.67597\n",
      "valid score: 0.59496\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_classifier = LGBMClassifier(random_state=0, learning_rate=0.012, n_estimators=190)\n",
    "lgbm_classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\n",
    "    \"train score: {:.5f}\".format(\n",
    "        roc_auc_score(y_train, lgbm_classifier.predict_proba(X_train)[:, 1])\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"valid score: {:.5f}\".format(\n",
    "        roc_auc_score(y_valid, lgbm_classifier.predict_proba(X_valid)[:, 1])\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.56084331, 0.43915669],\n",
       "       [0.57333006, 0.42666994],\n",
       "       [0.56516231, 0.43483769],\n",
       "       ...,\n",
       "       [0.50313453, 0.49686547],\n",
       "       [0.5599558 , 0.4400442 ],\n",
       "       [0.69606248, 0.30393752]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features = [\n",
    "    preprocessor(page_content)\n",
    "    for page_content in pd.read_csv(\"test.csv\")[\"Page content\"]\n",
    "]\n",
    "df_test = pd.DataFrame(\n",
    "    test_features,\n",
    "    columns=[\n",
    "        \"title\",\n",
    "        \"topic\",\n",
    "        \"author_name\",\n",
    "        \"year\",\n",
    "        \"month\",\n",
    "        \"day\",\n",
    "        \"hour\",\n",
    "        \"content_len\",\n",
    "        \"see_also\",\n",
    "        \"see_also_num\",\n",
    "        \"contents\",\n",
    "        \"weekday\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "X_test = transformer.transform(df_test.values)\n",
    "y_pred = lgbm_classifier.predict_proba(X_test)\n",
    "y_pred\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
